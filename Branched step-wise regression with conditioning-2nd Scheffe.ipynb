{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as st\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(experimental_file, response_file, response):\n",
    "    'imports data'\n",
    "    'experimental_file = experimental design csv filename i.e experimental.csv'\n",
    "    'response_file = results csv filename i.e Response.csv'\n",
    "    'response = reponse name: i.e rheomix final deg time min or rheomix stability time min'\n",
    "    \n",
    "    experimental_df = pd.read_csv(experimental_file)\n",
    "    response_df = pd.read_csv(response_file)\n",
    "    \n",
    "    X = experimental_df[experimental_df.columns.values.tolist()[1:]].values\n",
    "    y = response_df[response].values\n",
    "    max1 = max(y)\n",
    "    min1 = min(y)\n",
    "\n",
    "    y_norm = [2*((i-min1)/(max1-min1)) - 1 for i in y]\n",
    "    \n",
    "    \n",
    "    X_linear = X\n",
    "    \n",
    "    return X, y_norm, X_linear, experimental_df, response_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(y, X_linear):\n",
    "    'fits model of all linear terms to obtain benchmark AIC'\n",
    "    'AIC_prev_min = AIC value of previous step in stepwise regression'\n",
    "    'AIC_cur_min = AIC value of current step in stepwise regression'\n",
    "    \n",
    "    model = sm.OLS(y, X_linear)\n",
    "    results = model.fit()\n",
    "    AIC_prev_min = st.eval_measures.aicc(results.llf, results.nobs, results.df_model) + 1\n",
    "    AIC_cur_min = st.eval_measures.aicc(results.llf, results.nobs, results.df_model)\n",
    "    \n",
    "    return AIC_prev_min, AIC_cur_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_type_func(array_, indexs):\n",
    "    \n",
    "    if len(indexs) == 2:\n",
    "        \n",
    "        if indexs[1]== 'inv' or indexs[1]== 'log':\n",
    "            \n",
    "            if indexs[1] == 'inv':\n",
    "                return 1/(array_[:, indexs[0]])\n",
    "            if indexs[1] == 'log':\n",
    "                return np.log(array_[:, indexs[0]])\n",
    "            \n",
    "        else:\n",
    "            return array_[:, indexs[0]]*array_[:, indexs[1]]\n",
    "\n",
    "    \n",
    "def model_terms_name(list_, terms, indexs):\n",
    "    \n",
    "    if len(terms) == 1:\n",
    "        \n",
    "        if indexs[1] == 'inv':\n",
    "            list_.append(['1' + '/' + terms[0],  indexs[0], indexs[1]])\n",
    "        if indexs[1] == 'log':\n",
    "            list_.append(['log' + '(' + terms[0] + ')',  indexs[0], indexs[1]])\n",
    "\n",
    "    \n",
    "    if len(terms) == 2:\n",
    "\n",
    "\n",
    "        list_.append([terms[0] + '*' + terms[1],  indexs[0], indexs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_terms_list(experimental_df, response_df, inv_log, linear_terms):\n",
    "    'creates list of terms with key in current model'\n",
    "    'creates list of possible terms with key to be added'\n",
    "    \n",
    "    \n",
    "    model_terms = []\n",
    "    for i in range(len(linear_terms)):\n",
    "\n",
    "        term = linear_terms[i]\n",
    "        key = i\n",
    "        model_terms.append([term, i])\n",
    "     \n",
    "    poss_terms = []\n",
    "    for i in range(len(linear_terms)):\n",
    "        for j in range(len(linear_terms)): \n",
    "            if i < j:\n",
    "                \n",
    "                model_terms_name(poss_terms, [linear_terms[i], linear_terms[j]], [i, j])\n",
    "       \n",
    "    \n",
    "    if inv_log == 'log' or inv_log == 'inv':\n",
    "\n",
    "        for i in range(len(linear_terms)):\n",
    "            model_terms_name(poss_terms, [linear_terms[i]], [i, inv_log])\n",
    "\n",
    "        \n",
    "    return model_terms, poss_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_gen(model, X_linear):\n",
    "\n",
    "    for i, j in enumerate(model):\n",
    "        \n",
    "        if i == 0 and len(j) == 2: \n",
    "            X_new = X_linear[:, model[0][1]]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if len(j) == 2:\n",
    "                add = X_linear[:, j[1]]\n",
    "\n",
    "            if len(j) == 3:\n",
    "                add = X_linear[:, j[1]]*X_linear[:, j[2]]\n",
    "\n",
    "            X_new2 = np.column_stack((X_new, add))\n",
    "            X_new = X_new2\n",
    "\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(experimental_file, response_file, response, inv_log, linear_terms, model_terms1, cond_limit, VIF_limit):\n",
    "\n",
    "    X1, y, X_linear1, experimental_df, response_df = import_data(experimental_file, response_file, response)\n",
    "    X = X_gen(model_terms1, X_linear1)\n",
    "    X_linear = X\n",
    "    \n",
    "    model_terms, poss_terms = model_terms_list(experimental_df, response_df, inv_log, linear_terms)\n",
    "\n",
    "    AIC_prev_min, AIC_cur_min = linear_fit(y, X_linear)\n",
    "\n",
    "    cntt = 0\n",
    "    cnt_start = 0\n",
    "    while AIC_cur_min < AIC_prev_min:\n",
    "\n",
    "        cntt += 1\n",
    "\n",
    "        AIC_prev_min = AIC_cur_min\n",
    "\n",
    "        cnt1 = 0\n",
    "        \n",
    "        for i in poss_terms:\n",
    "\n",
    "            if i[-1] == 'log' or i[-1] == 'inv':\n",
    "                hierachy_compl = 1\n",
    "\n",
    "            else:\n",
    "                TEST_MODEL = copy.deepcopy(model_terms)\n",
    "                for index_x, x in enumerate(TEST_MODEL):\n",
    "                    if x[-1] == 'log' or x[-1] == 'inv':\n",
    "                        del TEST_MODEL[index_x]\n",
    "\n",
    "                for x in TEST_MODEL:\n",
    "                    del x[0]\n",
    "                    x.sort()\n",
    "                TEST_TERM = i[1:]\n",
    "                TEST_TERMS = []\n",
    "                for k in range(len(TEST_TERM)-1):\n",
    "                    for l in combinations(TEST_TERM, k+1):\n",
    "                        l2 = list(l)\n",
    "                        l2.sort()\n",
    "                        TEST_TERMS.append(l2)\n",
    "\n",
    "                hierachy_compl = 0\n",
    "                if all(item in TEST_MODEL for item in TEST_TERMS):\n",
    "                    hierachy_compl = 1\n",
    "\n",
    "\n",
    "            if hierachy_compl == 1:\n",
    "\n",
    "\n",
    "                if len(i) == 2:\n",
    "\n",
    "                    j = i[1]\n",
    "                    add_term_cur = X_linear[:, j]\n",
    "\n",
    "                else:\n",
    "                    add_term_cur = model_type_func(X_linear, i[1:])\n",
    "\n",
    "                X_new = np.column_stack((X, add_term_cur))\n",
    "                new_model = sm.OLS(y, X_new)\n",
    "                new_results = new_model.fit()\n",
    "                AIC = st.eval_measures.aicc(new_results.llf, new_results.nobs, new_results.df_model)\n",
    "                COND = new_results.condition_number\n",
    "\n",
    "                variables = new_model.exog\n",
    "                vif = [variance_inflation_factor(variables, m) for m in range(variables.shape[1])]\n",
    "                vif_max = max(vif)\n",
    "\n",
    "\n",
    "                if AIC < AIC_cur_min and COND < cond_limit and vif_max < VIF_limit:\n",
    "\n",
    "                    AIC_cur_min = AIC\n",
    "                    X_updated = X_new\n",
    "                    term_key = i \n",
    "                    results = new_results\n",
    "                    cnt1 = 1\n",
    "                    vif2 = vif_max\n",
    "\n",
    "        if AIC_cur_min < AIC_prev_min and cnt1 == 1:\n",
    "\n",
    "            model_terms.append(term_key)\n",
    "            X = X_updated\n",
    "            poss_terms.remove(term_key)\n",
    "            final = results\n",
    "            cnt_start = 1\n",
    "            vif_max1 = vif2\n",
    "\n",
    "        \n",
    "\n",
    "        cnt2 = 0\n",
    "        for i, j in enumerate(model_terms):\n",
    "            if len(model_terms) > 1:\n",
    "                if j[-1] == 'log' or j[-1] == 'inv':\n",
    "                    hierachy_max = 1\n",
    "\n",
    "                else:\n",
    "\n",
    "                    hierachy_max = 1\n",
    "                    for k in model_terms:\n",
    "                        if len(k) > len(j):\n",
    "                            if any(x in j for x in k):\n",
    "                                hierachy_max = 0\n",
    "\n",
    "                if hierachy_max == 1:\n",
    "\n",
    "                    X_new = np.delete(X, i, axis = 1)\n",
    "\n",
    "\n",
    "                    new_model = sm.OLS(y, X_new)\n",
    "                    new_results = new_model.fit()\n",
    "                    AIC = st.eval_measures.aicc(new_results.llf, new_results.nobs, new_results.df_model)\n",
    "                    COND = new_results.condition_number\n",
    "                    if len(model_terms) > 2:\n",
    "                        variables = new_model.exog\n",
    "                        vif = [variance_inflation_factor(variables, m) for m in range(variables.shape[1])]\n",
    "                        vif_max = max(vif)\n",
    "                    else: \n",
    "                        vif_max = 0\n",
    "\n",
    "\n",
    "\n",
    "                    if AIC < AIC_cur_min:\n",
    "\n",
    "                        AIC_cur_min = AIC\n",
    "                        X_updated = X_new\n",
    "                        term_key = j\n",
    "\n",
    "                        sol_results = new_results\n",
    "                        cnt2 = 1\n",
    "                        vif2 = vif_max\n",
    "\n",
    "\n",
    "        if AIC_cur_min < AIC_prev_min and cnt2 == 1:\n",
    "\n",
    "\n",
    "            model_terms.remove(term_key)\n",
    "            X = X_updated\n",
    "            poss_terms.append(term_key)\n",
    "            final = sol_results\n",
    "            cnt_start = 1\n",
    "            vif_max1 = vif2\n",
    "            \n",
    "    if cnt_start == 0:\n",
    "        new_model = sm.OLS(y, X_linear)\n",
    "        final = new_model.fit()\n",
    "        AIC_cur_min = st.eval_measures.aicc(final.llf, final.nobs, final.df_model)\n",
    "        if len(model_terms) != 1:\n",
    "            variables = new_model.exog\n",
    "            vif = [variance_inflation_factor(variables, m) for m in range(variables.shape[1])]\n",
    "            vif_max1 = max(vif)\n",
    "        else: \n",
    "            vif_max1 = 0\n",
    "\n",
    "        \n",
    "    AICc_final = AIC_cur_min\n",
    "    return AICc_final, final, model_terms, X, y, poss_terms, vif_max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_iteration(experimental_file, response_file, response, inv_log, cond_limit, VIF_limit):\n",
    "\n",
    "    experimental_df = pd.read_csv(experimental_file)\n",
    "    linear_terms = experimental_df.columns.values.tolist()[1:]\n",
    "    \n",
    "    lin_terms = []\n",
    "    for i in range(len(linear_terms)):\n",
    "        term = linear_terms[i]\n",
    "        key = i\n",
    "        lin_terms.append(term)\n",
    "        \n",
    "    AICc_prev = 1000\n",
    "    cnt = 0\n",
    "    for i in range(len(lin_terms)):\n",
    "        for j in combinations(lin_terms, i+1):\n",
    "            linear_terms = list(j)\n",
    "            model_terms1 = []\n",
    "            for k in linear_terms:\n",
    "                key1 = lin_terms.index(k)\n",
    "                model_terms1.append([k, key1])\n",
    "                \n",
    "            AICc, final1, terms, X, y, poss, VIF = model_fit(experimental_file, response_file, response, inv_log, linear_terms, model_terms1, cond_limit, VIF_limit)\n",
    "            \n",
    "            if AICc < AICc_prev and final1.condition_number < cond_limit and VIF < VIF_limit:\n",
    "\n",
    "                AICc_prev = AICc\n",
    "                AICc_final, final1_final, terms_final, X_final, y_final, poss_final = AICc, final1, terms, X, y, poss\n",
    "                \n",
    "    return AICc_final, final1_final, terms_final, X_final, y_final, poss_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16.53370090020981,\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                  OLS Regression Results                                \n",
       " =======================================================================================\n",
       " Dep. Variable:                      y   R-squared (uncentered):                   0.886\n",
       " Model:                            OLS   Adj. R-squared (uncentered):              0.866\n",
       " Method:                 Least Squares   F-statistic:                              43.51\n",
       " Date:                Sun, 24 Oct 2021   Prob (F-statistic):                    1.76e-16\n",
       " Time:                        17:49:47   Log-Likelihood:                         0.20683\n",
       " No. Observations:                  46   AIC:                                      13.59\n",
       " Df Residuals:                      39   BIC:                                      26.39\n",
       " Df Model:                           7                                                  \n",
       " Covariance Type:            nonrobust                                                  \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " x1            -1.2401      0.453     -2.737      0.009      -2.156      -0.324\n",
       " x2            -0.6730      0.421     -1.600      0.118      -1.524       0.178\n",
       " x3             8.3295      4.237      1.966      0.056      -0.240      16.899\n",
       " x4            -1.5095      0.857     -1.761      0.086      -3.244       0.225\n",
       " x5            -7.0130      6.117     -1.146      0.259     -19.386       5.361\n",
       " x6           106.5174     23.086      4.614      0.000      59.821     153.214\n",
       " x7          -278.1469     99.508     -2.795      0.008    -479.422     -76.872\n",
       " ==============================================================================\n",
       " Omnibus:                       11.296   Durbin-Watson:                   1.180\n",
       " Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.551\n",
       " Skew:                           0.964   Prob(JB):                      0.00310\n",
       " Kurtosis:                       4.520   Cond. No.                     1.49e+03\n",
       " ==============================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " [2] The condition number is large, 1.49e+03. This might indicate that there are\n",
       " strong multicollinearity or other numerical problems.\n",
       " \"\"\",\n",
       " [['Xpvc', 0],\n",
       "  ['Xfiller', 1],\n",
       "  ['Xstabiliser', 2],\n",
       "  ['Xdinp', 3],\n",
       "  ['Xldh', 4],\n",
       "  ['Xdinp*Xldh', 3, 4],\n",
       "  ['Xstabiliser*Xldh', 2, 4]],\n",
       " array([  -1.24011652,   -0.67301471,    8.32954725,   -1.50947066,\n",
       "          -7.0129803 ,  106.51735799, -278.14694138]),\n",
       " [['Xpvc*Xfiller', 0, 1],\n",
       "  ['Xpvc*Xstabiliser', 0, 2],\n",
       "  ['Xpvc*Xdinp', 0, 3],\n",
       "  ['Xpvc*Xldh', 0, 4],\n",
       "  ['Xpvc*Xsph', 0, 5],\n",
       "  ['Xfiller*Xstabiliser', 1, 2],\n",
       "  ['Xfiller*Xdinp', 1, 3],\n",
       "  ['Xfiller*Xldh', 1, 4],\n",
       "  ['Xfiller*Xsph', 1, 5],\n",
       "  ['Xstabiliser*Xdinp', 2, 3],\n",
       "  ['Xstabiliser*Xsph', 2, 5],\n",
       "  ['Xdinp*Xsph', 3, 5],\n",
       "  ['Xldh*Xsph', 4, 5],\n",
       "  ['Xsph', 5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'model_fit(experimental_file, response_file, response, inv_log, cond_limit, VIF_limit)'\n",
    "\n",
    "'repsonse = rheomix final deg time min or rheomix stability time min'\n",
    "test1 = 'rheomix final deg time min'\n",
    "test2 = 'rheomix stability time min'\n",
    "cond_limit = 1500 #conditioning number limit\n",
    "VIF_limit = 100 #VIF limit\n",
    "\n",
    "'inv_log = inv, log or None to add inverse terms, log terms or neither'\n",
    "\n",
    "AICc, final, terms, X, y, poss = model_iteration('experimental.csv', 'Response.csv', test1,  None, cond_limit, VIF_limit)\n",
    "AICc, final.summary(), terms, final.params, poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
